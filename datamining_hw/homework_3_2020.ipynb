{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Double Click here to edit this cell***\n",
    "\n",
    "- Name: 김수연\n",
    "- Student ID: 201800839\n",
    "- Submission date: 2020 5/1 금"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remark: gradient_descent.py, linear_algebra.py must be in the folder having this notebook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "from gradient_descent import *\n",
    "from linear_algebra import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (5 pts)\n",
    "\n",
    "- The following function has a minimum at $(2, 3)$\n",
    "$$\n",
    "f(x_1, x_2) = (x_1 - 2)^2 + (x_2 - 3)^2\n",
    "$$\n",
    "\n",
    "- We want to compute the minimum of $f$ using the gradient descent algorithm\n",
    "- Define a function (```f```) and gradient of function (```f_gradient```)\n",
    "- **Do NOT use numpy functions to define f and f_gradient**\n",
    "- **USE functions in linear_algebra.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE MUST BE HERE\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"fuction of Problem1\"\"\"\n",
    "    return (x[0]-2)**2 + (x[1]-3)**2\n",
    "    \n",
    "def f_gradient(x):\n",
    "    \"\"\"deviation of f(x)\"\"\"\n",
    "    return [2.0*x[0]-4, 2.0*x[1]-6]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 996 µs\n",
      "solution is [1.997524119921429, 2.996286179882144]\n",
      "++++++++++ Problem 1 check passed ++++++++++\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "init_x = [0.,0.]\n",
    "%time solution = minimize_batch(f, f_gradient, init_x, tolerance=0.00001)\n",
    "\n",
    "### correctness check\n",
    "print('solution is {}'.format(solution))\n",
    "EPSILON = 0.01\n",
    "cond1 = math.fabs(solution[0] - 2.0) <= EPSILON\n",
    "cond2 = math.fabs(solution[1] - 3.0) <= EPSILON\n",
    "assert  all([cond1, cond2]), '-'*10 + ' Problem 1 check failed ' + '-'*10\n",
    "print('+'*10 + ' Problem 1 check passed ' + '+'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (10 pts)\n",
    "\n",
    "- The centroid of a finite set of $\\displaystyle {k}$ points $\\displaystyle \\mathbf {x} _{1},\\mathbf {x} _{2},\\ldots ,\\mathbf {x} _{k}$ in $\\displaystyle \\mathbb {R} ^{n}$ is\n",
    "$$\n",
    "\\mathbf {C} ={\\frac {\\mathbf {x} _{1}+\\mathbf {x} _{2}+\\cdots +\\mathbf {x} _{k}}{k}}\n",
    "$$\n",
    "\n",
    "- We want to compute a centroid by **minimizing the mean of squared Euclidean distances between itself and each point in the set**\n",
    "$$\n",
    "x_{\\text{centroid}} = \\text{argmin}_{\\text{c}} {\\frac{\\sum_{i=1}^{n}d({\\text{c}}, x_i)^2}{n}}\n",
    "$$\n",
    "- Define a function (```sq_dist```) and gradient of function (```sq_dist_gradient```)\n",
    "- **Do NOT use numpy functions to define sq_dist and sq_dist_gradient**\n",
    "- **USE functions in linear_algebra.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE MUST BE HERE\n",
    "\n",
    "def sq_dist(c, X):\n",
    "    \"\"\"The mean of squared Euclidean distances between itself and each point in the set\"\"\"\n",
    "    return sum((c[0]-X_i[0])**2 + (c[1]-X_i[1])**2 for X_i in X)/len(X)\n",
    "    \n",
    "    \n",
    "\n",
    "def sq_dist_gradient(c, X):\n",
    "    \"\"\"derivative of sq_dist\"\"\"\n",
    "    return [sum(2*(c[0]-X_i[0]) for X_i in X)/len(X),\n",
    "            sum(2*(c[1]-X_i[1]) for X_i in X)/len(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 147 ms\n",
      "solution is [99.99885075808739, 700.1414374609791]\n",
      "++++++++++ Problem 2 check passed ++++++++++\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "c = np.array([100,700])\n",
    "X = c + np.random.randn(100,2)\n",
    "\n",
    "f = partial(sq_dist, X=X)\n",
    "gradient_f = partial(sq_dist_gradient, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "%time solution = minimize_batch(f, gradient_f, init_x)\n",
    "\n",
    "### correctness check\n",
    "print('solution is {}'.format(solution))\n",
    "EPSILON = 1\n",
    "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
    "assert  all([cond1, cond2]), '-'*10 + ' Problem 2 check failed ' + '-'*10\n",
    "print('+'*10 + ' Problem 2 check passed ' + '+'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 58s\n",
      "solution is [99.99988468682913, 700.0052527466843]\n",
      "++++++++++ Problem 2 check passed ++++++++++\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "c = np.array([100,700])\n",
    "X = c + np.random.randn(100000,2)     # 100 thousands\n",
    "\n",
    "f = partial(sq_dist, X=X)\n",
    "gradient_f = partial(sq_dist_gradient, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "%time solution = minimize_batch(f, gradient_f, init_x)\n",
    "\n",
    "### correctness check\n",
    "print('solution is {}'.format(solution))\n",
    "EPSILON = 1\n",
    "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
    "assert  all([cond1, cond2]), '+'*10 + ' Problem 2 check failed ' + '-'*10\n",
    "print('+'*10 + ' Problem 2 check passed ' + '+'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time taken in my computer**:\n",
    "```\n",
    "CPU times: user 2min 48s, sys: 951 ms, total: 2min 49s\n",
    "Wall time: 2min 49s\n",
    "solution is [99.99988468682913, 700.0052527466843]\n",
    "++++++++++ Problem 2 check passed ++++++++++\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (10 pts)\n",
    "\n",
    "- Continued from Problem 2\n",
    "- We want to compute a centroid\n",
    "- Define a function (```sq_dist_numpy```) and gradient of function (```sq_dist_gradient_numpy```)\n",
    "- **Use numpy functions to define sq_dist and sq_dist_gradient**\n",
    "- **Do NOT use functions in linear_algebra.py**\n",
    "- Your point will be 10 : wall time is less than or equal to 4s\n",
    "- Otherwise, your point will be 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sq_dist_numpy(c, X):\n",
    "    \"\"\"sq_dist numpy version\"\"\"\n",
    "    c = np.array(c)\n",
    "    X = np.array(X)\n",
    "    return np.sum((c - X)**2)/len(X)\n",
    "    # YOUR CODE MUST BE HERE\n",
    "\n",
    "def sq_dist_gradient_numpy(c, X):\n",
    "    \"\"\"sq_dist_gradient numpy version\"\"\"\n",
    "    c = np.array(c)\n",
    "    X = np.array(X)\n",
    "    return np.sum(2*(c-X), axis=0)/len(X)\n",
    "    # YOUR CODE MUST BE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.08 s\n",
      "[99.99988468682913, 700.0052527466843]\n",
      "++++++++++ Problem 3 check passed ++++++++++\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "np.random.seed(0)\n",
    "c = np.array([100,700])\n",
    "X = c + np.random.randn(100000,2)\n",
    "\n",
    "f = partial(sq_dist_numpy, X=X)\n",
    "gradient_f = partial(sq_dist_gradient_numpy, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "%time solution = minimize_batch(f, gradient_f, init_x)\n",
    "\n",
    "### correctness check\n",
    "print(solution)\n",
    "EPSILON = 1\n",
    "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
    "assert  all([cond1, cond2]), '-'*10 + ' Problem 3 check failed ' + '-'*10\n",
    "print('+'*10 + ' Problem 3 check passed ' + '+'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time taken in my computer**:\n",
    "```\n",
    "CPU times: user 1.98 s, sys: 3.8 ms, total: 1.99 s\n",
    "Wall time: 2 s\n",
    "[99.99988468682913, 700.0052527466843]\n",
    "++++++++++ Problem 3 check passed ++++++++++\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (10 pts)\n",
    "\n",
    "- We want to compute a centroid using Manhattan distance\n",
    "- Define a function (```abs_diff_numpy```) and gradient of function (```abs_diff_gradient_numpy```)\n",
    "- Use numpy functions to define abs_diff_numpy and abs_diff_gradient_numpy\n",
    "- Do NOT use functions in linear_algebra.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manhattan distance\n",
    "import numpy as np\n",
    "\n",
    "def abs_diff_numpy(c, X):\n",
    "    \"\"\"compute a centroid using Manhattan distance. mean of sum( |c[0] - X[0]| + |c[1] - X[0]| )\"\"\"\n",
    "    c = np.array(c)\n",
    "    X = np.array(X)\n",
    "    # YOUR CODE MUST BE HERE\n",
    "    return np.sum(np.fabs(c-X))/len(X)\n",
    "\n",
    "def abs_diff_gradient_numpy(c, X):\n",
    "    \"\"\"derivative of abs_diff_numpy. each derivative is 1+1 or 1-1 or -1+1 or -1-1\"\"\"\n",
    "    c = np.array(c)\n",
    "    X = np.array(X)\n",
    "    # YOUR CODE MUST BE HERE\n",
    "    M = c-X\n",
    "    M[M >= 0] = 1\n",
    "    M[M < 0] = -1\n",
    "    return np.sum(M, axis=0)/len(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.98 ms\n",
      "[99.26, 99.34666666666666]\n",
      "++++++++++ Problem 4 check passed ++++++++++\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "np.random.seed(0)\n",
    "# c = np.array([100,700])\n",
    "# X = c + np.random.randn(100,2)\n",
    "c1 = np.array([100,100])\n",
    "X1 = c1 + np.random.randn(100,2)\n",
    "c2 = np.array([100,0])\n",
    "X2 = c2 + np.random.randn(100,2)\n",
    "c3 = np.array([0,100])\n",
    "X3 = c3 + np.random.randn(100,2)\n",
    "X  = np.vstack((X1, X2, X3)) \n",
    "\n",
    "f = partial(abs_diff_numpy, X=X)\n",
    "gradient_f = partial(abs_diff_gradient_numpy, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "%time solution = minimize_batch(f, gradient_f, init_x)\n",
    "\n",
    "### correctness check\n",
    "print(solution)\n",
    "EPSILON = 1\n",
    "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "cond2 = math.fabs(solution[1] - 100.0) <= EPSILON\n",
    "assert  all([cond1, cond2]), '-'*10 + ' Problem 4 check failed ' + '-'*10\n",
    "print('+'*10 + ' Problem 4 check passed ' + '+'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 (15 pts)\n",
    "\n",
    "- We want to rewrite ```minimize_batch```.\n",
    "- Do NOT use ```step``` function; provide numpy style code using broadcasting\n",
    "    - Do NOT use ```[step(theta, gradient, -step_size) for step_size in step_sizes]```\n",
    "- Modify ```minimize_batch``` to take ```step_sizes``` as an argument\n",
    "- Modify ```minimize_batch``` to take maximum number of epochs as an argument\n",
    "    - epoch is the number of ```while``` loop iterations in the following code.\n",
    "- Modify ```minimize_batch``` to return ```epoch``` together with ```theta```\n",
    "- Modify ```minimize_batch``` to return ```None``` as solution if it does not converge within max_steps\n",
    "- **Use numpy functions to define sq_dist_numpy_1 and sq_dist_gradient_numpy_1**\n",
    "- **Do NOT use functions in linear_algebra.py**\n",
    "- If all done, now you have an enhanced numpy version of minimize_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is ```minimize_batch``` in our textbook\n",
    "```python\n",
    "def minimize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "    \"\"\"use gradient descent to find theta that minimizes target function\"\"\"\n",
    "\n",
    "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "    theta = theta_0                           # set theta to initial value\n",
    "    target_fn = safe(target_fn)               # safe version of target_fn\n",
    "    value = target_fn(theta)                  # value we're minimizing\n",
    "\n",
    "    while True:\n",
    "        gradient = gradient_fn(theta)\n",
    "        next_thetas = [step(theta, gradient, -step_size)\n",
    "                       for step_size in step_sizes]\n",
    "\n",
    "        # choose the one that minimizes the error function\n",
    "        next_theta = min(next_thetas, key=target_fn)\n",
    "        next_value = target_fn(next_theta)\n",
    "\n",
    "        # stop if we're \"converging\"\n",
    "        if abs(value - next_value) < tolerance:\n",
    "            return theta\n",
    "        else:\n",
    "            theta, value = next_theta, next_value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_batch_enhanced(target_fn, gradient_fn, theta_0, step_sizes, max_steps=10000, tolerance=0.000001):\n",
    "    \"\"\"minimize_batch() using numpy. faster than using linalg.\n",
    "    next_thetas를 구할 때, numpy 행렬들을 2차원으로 바꾼 뒤, broadcasting을 사용해 연산했다.\n",
    "    while이 max_steps만큼 돌면 solution 값으로 None을 반환한다.(=> 적절하지 않은 step_size)\"\"\"\n",
    "    # YOUR CODE MUST BE HERE \n",
    "    theta = theta_0\n",
    "    target_fn = safe(target_fn)\n",
    "    value = target_fn(theta)\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        next_thetas = (theta[:, np.newaxis] - gradient_fn(theta)[:, np.newaxis]*step_sizes[np.newaxis, :]).T\n",
    "        \n",
    "        next_theta = min(next_thetas, key=target_fn)\n",
    "        next_value = target_fn(next_theta)\n",
    "        \n",
    "        \n",
    "        if abs(value - next_value) < tolerance:\n",
    "            return theta, epoch\n",
    "        else:\n",
    "            theta, value = next_theta, next_value\n",
    "            epoch += 1\n",
    "            if(epoch == max_steps):\n",
    "                return None, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE MUST BE HERE\n",
    "def sq_dist_numpy_1(c, X):\n",
    "    \"\"\"same function in Problem3\"\"\"\n",
    "    c = np.array(c)\n",
    "    X = np.array(X)\n",
    "    return np.sum((c - X)**2)/len(X)\n",
    "\n",
    "def sq_dist_gradient_numpy_1(c, X):\n",
    "    \"\"\"same derivative of function in Problem3\"\"\"\n",
    "    c = np.array(c)\n",
    "    X = np.array(X)\n",
    "    return np.sum(2*(c-X), axis=0)/len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
      "Problem 5 check passed\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "c = np.array([100,700])\n",
    "X = c + 10*np.random.randn(1000,2)\n",
    "\n",
    "f = partial(sq_dist_numpy_1, X=X)\n",
    "gradient_f = partial(sq_dist_gradient_numpy_1, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "step_sizes = np.array([0.01])\n",
    "\n",
    "solution, epoch = minimize_batch_enhanced(f, gradient_f, init_x, step_sizes)\n",
    "### correctness check\n",
    "if solution is None:\n",
    "    print('Does not converge within epoch {}'.format(epoch))\n",
    "else:\n",
    "    print('Solution {} found at epoch {}'.format(solution, epoch))\n",
    "    EPSILON = 1\n",
    "    cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "    cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
    "    assert  all([cond1, cond2]), 'Problem 5 check failed'\n",
    "    print('Problem 5 check passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your solution should be like:\n",
    "```\n",
    "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
    "Problem 5 check passed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++ Test case [10] ++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda2020\\lib\\site-packages\\numpy\\core\\fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\user\\Anaconda2020\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in square\n",
      "  \"\"\"\n",
      "C:\\Users\\user\\Anaconda2020\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "C:\\Users\\user\\Anaconda2020\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in subtract\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does not converge within epoch 10000\n",
      "\n",
      "++++++++++ Test case [0.1] ++++++++++\n",
      "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
      "Problem 5 check passed\n",
      "\n",
      "++++++++++ Test case [0.01] ++++++++++\n",
      "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
      "Problem 5 check passed\n",
      "\n",
      "++++++++++ Test case [0.001] ++++++++++\n",
      "Solution [ 99.78040508 699.88532482] found at epoch 5349\n",
      "Problem 5 check passed\n",
      "\n",
      "++++++++++ Test case [0.0001] ++++++++++\n",
      "Does not converge within epoch 10000\n",
      "\n",
      "++++++++++ Test case [1.e-05] ++++++++++\n",
      "Does not converge within epoch 10000\n",
      "\n",
      "++++++++++ Test case [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03] ++++++++++\n",
      "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
      "Problem 5 check passed\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "c = np.array([100,700])\n",
    "X = c + 10*np.random.randn(1000,2)\n",
    "\n",
    "f = partial(sq_dist_numpy_1, X=X)\n",
    "gradient_f = partial(sq_dist_gradient_numpy_1, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "step_sizes_set = [np.array([10]),\n",
    "                  np.array([0.1]),\n",
    "                  np.array([0.01]),\n",
    "                  np.array([0.001]), \n",
    "                  np.array([0.0001]),\n",
    "                  np.array([0.00001]),\n",
    "                  np.array(np.logspace(-3,3,7))\n",
    "                 ]\n",
    "\n",
    "for step_sizes in step_sizes_set:\n",
    "    print()\n",
    "    print('+'*10 + ' Test case {} '.format(step_sizes) + '+'*10)\n",
    "    solution, epoch = minimize_batch_enhanced(f, gradient_f, init_x, step_sizes)\n",
    "    ### correctness check\n",
    "    if solution is None:\n",
    "        print('Does not converge within epoch {}'.format(epoch))\n",
    "    else:\n",
    "        print('Solution {} found at epoch {}'.format(solution, epoch))\n",
    "        EPSILON = 1\n",
    "        cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "        cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
    "        assert  all([cond1, cond2]), 'Problem 5 check failed'\n",
    "        print('Problem 5 check passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your solution should be like:\n",
    "```\n",
    "++++++++++ Test case [10] ++++++++++\n",
    "...\n",
    "Numpy overflow warning\n",
    "...\n",
    "Does not converge within epoch 10000\n",
    "\n",
    "++++++++++ Test case [0.1] ++++++++++\n",
    "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
    "Problem 5 check passed\n",
    "\n",
    "++++++++++ Test case [0.01] ++++++++++\n",
    "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
    "Problem 5 check passed\n",
    "\n",
    "++++++++++ Test case [0.001] ++++++++++\n",
    "Solution [ 99.78040508 699.88532482] found at epoch 5349\n",
    "Problem 5 check passed\n",
    "\n",
    "++++++++++ Test case [0.0001] ++++++++++\n",
    "Does not converge within epoch 10000\n",
    "\n",
    "++++++++++ Test case [1.e-05] ++++++++++\n",
    "Does not converge within epoch 10000\n",
    "\n",
    "++++++++++ Test case [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03] ++++++++++\n",
    "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
    "Problem 5 check passed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double click this cell to edit:\n",
    "\n",
    "What is your conclusion from experimets with the above several test cases?\n",
    "```\n",
    "위와 같이 Test case를 실행해 본 결과, step_size가 너무 커도 그리고 너무 작아도 최솟값이 되는 점을 찾아낼 수 없다는 것을 알 수 있었다. 위의 Test case에서는 step size가 10일 때 solution을 찾지 못했고, 0.1, 0.01, 0.001일 때 solution을 찾았으며, 1.e-04, 1.e-05일 때 solution을 찾지 못했다. 따라서 원하는 결과를 얻기 위해서는 step_size를 적절하게 설정해야만 한다. 하지만 함수별로 적절한 step size는 달라질 수 있다. 따라서 마지막 Test case처럼 다양한 크기의 step_size를 같이 적용시켜야, 시간은 좀 걸릴지라도 안전하게 원하는 결과를 얻을 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics:\n",
    "If you cheat, you will get negatgive of the total points.\n",
    "If the homework total is 22 and you cheat, you get -22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to submit\n",
    "- Run **all cells**\n",
    "- Goto \"File -> Print Preview\"\n",
    "- Print the page as pdf\n",
    "- Submit the pdf file in google classroom\n",
    "- No late homeworks accepted\n",
    "- Your homework will be graded on the basis of correctness and programming skills"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
